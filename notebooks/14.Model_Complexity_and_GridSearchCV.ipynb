{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter selection, Validation, and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most models have parameters that influence how complex a model they can learn. Remember using `KNeighborsRegressor`.\n",
    "If we change the number of neighbors we consider, we get a smoother and smoother prediction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/plot_kneigbors_regularization.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above figure, we see fits for three different values of ``n_neighbors``.\n",
    "For ``n_neighbors=2``, the data is overfit, the model is too flexible and can adjust too much to the noise in the training data. For ``n_neighbors=20``, the model is not flexible enough, and can not model the variation in the data appropriately.\n",
    "\n",
    "In the middle, for ``n_neighbors = 5``, we have found a good mid-point. It fits\n",
    "the data fairly well, and does not suffer from the overfit or underfit\n",
    "problems seen in the figures on either side. What we would like is a\n",
    "way to quantitatively identify overfit and underfit, and optimize the\n",
    "hyperparameters (in this case, the polynomial degree d) in order to\n",
    "determine the best algorithm.\n",
    "\n",
    "We trade off remembering too much about the particularities and noise of the training data vs. not modeling enough of the variability. This is a trade-off that needs to be made in basically every machine learning application and is a central concept, called bias-variance-tradeoff or \"overfitting vs underfitting\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/overfitting_underfitting_cartoon.svg\" width=\"100%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters, Over-fitting, and Under-fitting\n",
    "\n",
    "Unfortunately, there is no general rule how to find the sweet spot, and so machine learning practitioners have to find the best trade-off of model-complexity and generalization by trying several hyperparameter settings. Hyperparameters are the internal knobs or tuning parameters of a machine learning algorithm (in contrast to model parameters that the algorithm learns from the training data -- for example, the weight coefficients of a linear regression model); the number of *k* in K-nearest neighbors is such a hyperparameter.\n",
    "\n",
    "Most commonly this \"hyperparameter tuning\" is done using a brute force search, for example over multiple values of ``n_neighbors``:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors: 1, average score: 0.510046\n",
      "n_neighbors: 3, average score: 0.707736\n",
      "n_neighbors: 5, average score: 0.738275\n",
      "n_neighbors: 10, average score: 0.737705\n",
      "n_neighbors: 20, average score: 0.621896\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "# generate toy dataset:\n",
    "x = np.linspace(-3, 3, 100)\n",
    "rng = np.random.RandomState(42)\n",
    "y = np.sin(4 * x) + x + rng.normal(size=len(x))\n",
    "X = x[:, np.newaxis]\n",
    "\n",
    "cv = KFold(shuffle=True)\n",
    "\n",
    "# for each parameter setting do cross-validation:\n",
    "for n_neighbors in [1, 3, 5, 10, 20]:\n",
    "    scores = cross_val_score(KNeighborsRegressor(n_neighbors=n_neighbors), X, y, cv=cv)\n",
    "    print(\"n_neighbors: %d, average score: %f\" % (n_neighbors, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for neigh: 1 score 0.401186\n",
      "for neigh: 3 score 0.587217\n",
      "for neigh: 5 score 0.702346\n",
      "for neigh: 10 score 0.678383\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.RandomState(seed=1234)\n",
    "x = np.linspace(-3,3,100)\n",
    "y = np.sin(4*x) + x + rng.normal(size=len(x))\n",
    "cv = KFold(shuffle=True)\n",
    "\n",
    "for n in [1,3,5,10]:\n",
    "    clf = KNeighborsRegressor(n)\n",
    "    score = cross_val_score(clf,X,y,cv=cv)\n",
    "    print(\"for neigh: %d score %f\"%(n,np.mean(score)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a function in scikit-learn, called ``validation_plot`` to reproduce the cartoon figure above. It plots one parameter, such as the number of neighbors, against training and validation error (using cross-validation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/h9lNyhAnrhHawAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114c4d160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "n_neighbors = [1, 3, 5, 10, 20, 50]\n",
    "train_scores, test_scores = validation_curve(KNeighborsRegressor(), X, y, param_name=\"n_neighbors\",\n",
    "                                             param_range=n_neighbors, cv=cv)\n",
    "plt.plot(n_neighbors, train_scores.mean(axis=1), 'b', label=\"train accuracy\")\n",
    "plt.plot(n_neighbors, test_scores.mean(axis=1), 'g', label=\"test accuracy\")\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of neighbors')\n",
    "plt.xlim([50, 0])\n",
    "plt.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    Note that many neighbors mean a \"smooth\" or \"simple\" model, so the plot uses a reverted x axis.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If multiple parameters are important, like the parameters ``C`` and ``gamma`` in an ``SVM`` (more about that later), all possible combinations are tried:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.001000, gamma: 0.001000, average score: -0.016961\n",
      "C: 0.001000, gamma: 0.010000, average score: -0.088171\n",
      "C: 0.001000, gamma: 0.100000, average score: -0.114576\n",
      "C: 0.001000, gamma: 1.000000, average score: -0.218600\n",
      "C: 0.010000, gamma: 0.001000, average score: -0.011690\n",
      "C: 0.010000, gamma: 0.010000, average score: -0.043442\n",
      "C: 0.010000, gamma: 0.100000, average score: 0.067971\n",
      "C: 0.010000, gamma: 1.000000, average score: 0.069476\n",
      "C: 0.100000, gamma: 0.001000, average score: -0.046008\n",
      "C: 0.100000, gamma: 0.010000, average score: 0.165017\n",
      "C: 0.100000, gamma: 0.100000, average score: 0.362262\n",
      "C: 0.100000, gamma: 1.000000, average score: 0.368202\n",
      "C: 1.000000, gamma: 0.001000, average score: 0.008916\n",
      "C: 1.000000, gamma: 0.010000, average score: 0.519652\n",
      "C: 1.000000, gamma: 0.100000, average score: 0.605516\n",
      "C: 1.000000, gamma: 1.000000, average score: 0.624304\n",
      "C: 10.000000, gamma: 0.001000, average score: 0.550381\n",
      "C: 10.000000, gamma: 0.010000, average score: 0.606755\n",
      "C: 10.000000, gamma: 0.100000, average score: 0.519265\n",
      "C: 10.000000, gamma: 1.000000, average score: 0.667041\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# each parameter setting do cross-validation:\n",
    "for C in [0.001, 0.01, 0.1, 1, 10]:\n",
    "    for gamma in [0.001, 0.01, 0.1, 1]:\n",
    "        scores = cross_val_score(SVR(C=C, gamma=gamma), X, y, cv=cv)\n",
    "        print(\"C: %f, gamma: %f, average score: %f\" % (C, gamma, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this is such a very common pattern, there is a built-in class for this in scikit-learn, ``GridSearchCV``. ``GridSearchCV`` takes a dictionary that describes the parameters that should be tried and a model to train.\n",
    "\n",
    "The grid of parameters is defined as a dictionary, where the keys are the parameters and the values are the settings to be tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=cv,verbose=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the great things about GridSearchCV is that it is a *meta-estimator*. It takes an estimator like SVR above, and creates a new estimator, that behaves exactly the same - in this case, like a regressor.\n",
    "So we can call ``fit`` on it, to train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] . C=0.001, gamma=0.001, score=-0.23465162365174108, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] . C=0.001, gamma=0.001, score=-0.08354817631030187, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] .. C=0.001, gamma=0.001, score=-0.4038748509661878, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] .. C=0.001, gamma=0.01, score=-0.23183824823504606, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] ... C=0.001, gamma=0.01, score=-0.0814156816196363, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] .... C=0.001, gamma=0.01, score=-0.402256337022286, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] ... C=0.001, gamma=0.1, score=-0.22114759300913867, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] ... C=0.001, gamma=0.1, score=-0.07200191633659614, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] ... C=0.001, gamma=0.1, score=-0.39516330651616816, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ..... C=0.001, gamma=1, score=-0.22384473176429087, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ..... C=0.001, gamma=1, score=-0.07322412743537154, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ..... C=0.001, gamma=1, score=-0.39662422578115986, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] .... C=0.01, gamma=0.001, score=-0.231500935990135, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] .. C=0.01, gamma=0.001, score=-0.08119965497481862, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] ... C=0.01, gamma=0.001, score=-0.4020900599557953, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] .... C=0.01, gamma=0.01, score=-0.2036551258032946, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] .. C=0.01, gamma=0.01, score=-0.060057677101767126, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] .... C=0.01, gamma=0.01, score=-0.3847824415814513, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] .... C=0.01, gamma=0.1, score=-0.09177576923925845, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] .... C=0.01, gamma=0.1, score=0.026905769045730388, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ...... C=0.01, gamma=0.1, score=-0.289893484877384, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] ....... C=0.01, gamma=1, score=-0.1124985208184397, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] ...... C=0.01, gamma=1, score=0.015767208585669046, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] ...... C=0.01, gamma=1, score=-0.30598689728424056, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ... C=0.1, gamma=0.001, score=-0.20034737504689248, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ... C=0.1, gamma=0.001, score=-0.05793094547186795, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] .... C=0.1, gamma=0.001, score=-0.3823139287579558, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] .... C=0.1, gamma=0.01, score=0.036652400607031566, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ..... C=0.1, gamma=0.01, score=0.12274237469237326, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] .... C=0.1, gamma=0.01, score=-0.12248837702331383, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ...... C=0.1, gamma=0.1, score=0.39240141721268373, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ....... C=0.1, gamma=0.1, score=0.3913484215004097, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ....... C=0.1, gamma=0.1, score=0.4132949689794274, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ......... C=0.1, gamma=1, score=0.3917523181125182, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ......... C=0.1, gamma=1, score=0.4012131287132501, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] .......... C=0.1, gamma=1, score=0.386924459763062, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ...... C=1, gamma=0.001, score=0.05912908609852019, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ...... C=1, gamma=0.001, score=0.13746922033036668, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ..... C=1, gamma=0.001, score=-0.10061368691568129, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ........ C=1, gamma=0.01, score=0.4640578017821281, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ........ C=1, gamma=0.01, score=0.5269959893016671, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ....... C=1, gamma=0.01, score=0.49879164091458483, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ......... C=1, gamma=0.1, score=0.4158267435473586, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ......... C=1, gamma=0.1, score=0.6014238801357372, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ......... C=1, gamma=0.1, score=0.6355057785080769, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] .......... C=1, gamma=1, score=0.49840015402194926, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ........... C=1, gamma=1, score=0.6775755547759446, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ............ C=1, gamma=1, score=0.711818058518375, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ...... C=10, gamma=0.001, score=0.4727101357831124, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ...... C=10, gamma=0.001, score=0.5362010367769561, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ...... C=10, gamma=0.001, score=0.5081924771013258, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ....... C=10, gamma=0.01, score=0.4429243902440978, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ....... C=10, gamma=0.01, score=0.5981704465947073, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ....... C=10, gamma=0.01, score=0.6093798345347752, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ....... C=10, gamma=0.1, score=0.36619866973866844, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ........ C=10, gamma=0.1, score=0.6173428497243061, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ........ C=10, gamma=0.1, score=0.6476817113143792, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .......... C=10, gamma=1, score=0.5592447359232657, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .......... C=10, gamma=1, score=0.7490439926754078, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .......... C=10, gamma=1, score=0.7971481887337467, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=3, random_state=None, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=3)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What ``fit`` does is a bit more involved then what we did above. First, it runs the same loop with cross-validation, to find the best parameter combination.\n",
    "Once it has the best combination, it runs fit again on all data passed to fit (without cross-validation), to built a single new model using the best parameter setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, as with all models, we can use ``predict`` or ``score``:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.09216002, -2.03279386, -1.98408641, -1.95086359, -1.93704813,\n",
       "       -1.94532739, -1.97687702, -2.03116503, -2.10585699, -2.19683752,\n",
       "       -2.29835563, -2.40329315, -2.50354621, -2.59050086, -2.65557545,\n",
       "       -2.69079628, -2.68936788, -2.64619795, -2.55833784, -2.42530337,\n",
       "       -2.24924772, -2.03496744, -1.78973355, -1.52295164, -1.24566754,\n",
       "       -0.96994605, -0.70816046, -0.47223786, -0.27290963, -0.1190174 ,\n",
       "       -0.0169223 ,  0.02994084,  0.02133174, -0.03972558, -0.1470795 ,\n",
       "       -0.2917877 , -0.46263478, -0.64679837, -0.8306216 , -1.0004424 ,\n",
       "       -1.14342592, -1.24834659, -1.30626903, -1.31108453, -1.25986884,\n",
       "       -1.1530394 , -0.99430315, -0.7903997 , -0.55065819, -0.2863976 ,\n",
       "       -0.01021012,  0.26482563,  0.52595134,  0.76150485,  0.96161689,\n",
       "        1.11878675,  1.22830287,  1.28848503,  1.30073624,  1.26940462,\n",
       "        1.20146724,  1.10605871,  0.99387635,  0.8765007 ,  0.76567431,\n",
       "        0.67258353,  0.60718666,  0.57762814,  0.5897723 ,  0.64688208,\n",
       "        0.74945909,  0.89525095,  1.07942187,  1.29487264,  1.53268752,\n",
       "        1.78267839,  2.03399149,  2.27573898,  2.49761712,  2.69047438,\n",
       "        2.84679716,  2.96108611,  3.03010394,  3.05298365,  3.03119515,\n",
       "        2.96837703,  2.87004837,  2.74322246,  2.59594956,  2.43681952,\n",
       "        2.27445616,  2.11703457,  1.97184987,  1.84496099,  1.74092728,\n",
       "        1.66264901,  1.61131504,  1.58645431,  1.58608107,  1.60691825])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "You can inspect the best parameters found by ``GridSearchCV`` in the ``best_params_`` attribute, and the best score in the ``best_score_`` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7003866300789313\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 1}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But you can investigate the performance and much more for each set of parameter values by accessing the `cv_results_` attributes. The `cv_results_` attribute is a dictionary where each key is a string and each value is array. It can therefore be used to make a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.deprecation.DeprecationDict"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_C', 'param_gamma', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score', 'split0_train_score', 'split1_train_score', 'split2_train_score', 'mean_train_score', 'std_train_score'])\n"
     ]
    }
   ],
   "source": [
    "print(grid.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/uksrivastava/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/uksrivastava/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/uksrivastava/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/uksrivastava/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/uksrivastava/anaconda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001281</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>-0.240631</td>\n",
       "      <td>-0.024212</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.001}</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.234652</td>\n",
       "      <td>-0.049211</td>\n",
       "      <td>-0.083548</td>\n",
       "      <td>-0.003248</td>\n",
       "      <td>-0.403875</td>\n",
       "      <td>-0.020176</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.130188</td>\n",
       "      <td>0.018980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001259</td>\n",
       "      <td>0.000772</td>\n",
       "      <td>-0.238437</td>\n",
       "      <td>-0.022304</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.01}</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.231838</td>\n",
       "      <td>-0.046968</td>\n",
       "      <td>-0.081416</td>\n",
       "      <td>-0.001299</td>\n",
       "      <td>-0.402256</td>\n",
       "      <td>-0.018647</td>\n",
       "      <td>0.000770</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.130412</td>\n",
       "      <td>0.018823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000867</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>-0.229355</td>\n",
       "      <td>-0.014318</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.1}</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.221148</td>\n",
       "      <td>-0.037621</td>\n",
       "      <td>-0.072002</td>\n",
       "      <td>0.007102</td>\n",
       "      <td>-0.395163</td>\n",
       "      <td>-0.012436</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.131401</td>\n",
       "      <td>0.018307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>-0.231157</td>\n",
       "      <td>-0.015625</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 0.001, 'gamma': 1}</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.223845</td>\n",
       "      <td>-0.039074</td>\n",
       "      <td>-0.073224</td>\n",
       "      <td>0.005818</td>\n",
       "      <td>-0.396624</td>\n",
       "      <td>-0.013618</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>0.131471</td>\n",
       "      <td>0.018382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>-0.238196</td>\n",
       "      <td>-0.022098</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 0.01, 'gamma': 0.001}</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.231501</td>\n",
       "      <td>-0.046725</td>\n",
       "      <td>-0.081200</td>\n",
       "      <td>-0.001095</td>\n",
       "      <td>-0.402090</td>\n",
       "      <td>-0.018474</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.018804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score param_C  \\\n",
       "0       0.001281         0.000472        -0.240631         -0.024212   0.001   \n",
       "1       0.001259         0.000772        -0.238437         -0.022304   0.001   \n",
       "2       0.000867         0.000483        -0.229355         -0.014318   0.001   \n",
       "3       0.000746         0.000729        -0.231157         -0.015625   0.001   \n",
       "4       0.000750         0.000457        -0.238196         -0.022098    0.01   \n",
       "\n",
       "  param_gamma                        params  rank_test_score  \\\n",
       "0       0.001  {'C': 0.001, 'gamma': 0.001}               20   \n",
       "1        0.01   {'C': 0.001, 'gamma': 0.01}               19   \n",
       "2         0.1    {'C': 0.001, 'gamma': 0.1}               16   \n",
       "3           1      {'C': 0.001, 'gamma': 1}               17   \n",
       "4       0.001   {'C': 0.01, 'gamma': 0.001}               18   \n",
       "\n",
       "   split0_test_score  split0_train_score  split1_test_score  \\\n",
       "0          -0.234652           -0.049211          -0.083548   \n",
       "1          -0.231838           -0.046968          -0.081416   \n",
       "2          -0.221148           -0.037621          -0.072002   \n",
       "3          -0.223845           -0.039074          -0.073224   \n",
       "4          -0.231501           -0.046725          -0.081200   \n",
       "\n",
       "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
       "0           -0.003248          -0.403875           -0.020176      0.000747   \n",
       "1           -0.001299          -0.402256           -0.018647      0.000770   \n",
       "2            0.007102          -0.395163           -0.012436      0.000291   \n",
       "3            0.005818          -0.396624           -0.013618      0.000179   \n",
       "4           -0.001095          -0.402090           -0.018474      0.000142   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "0        0.000053        0.130188         0.018980  \n",
       "1        0.000356        0.130412         0.018823  \n",
       "2        0.000070        0.131401         0.018307  \n",
       "3        0.000348        0.131471         0.018382  \n",
       "4        0.000066        0.130435         0.018804  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cv_results = pd.DataFrame(grid.cv_results_)\n",
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.700387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.627956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.549568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.549086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.541966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_C param_gamma  mean_test_score\n",
       "19      10           1         0.700387\n",
       "15       1           1         0.627956\n",
       "14       1         0.1         0.549568\n",
       "17      10        0.01         0.549086\n",
       "18      10         0.1         0.541966"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_tiny = cv_results[['param_C', 'param_gamma', 'mean_test_score']]\n",
    "cv_results_tiny.sort_values(by='mean_test_score', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a problem with using this score for evaluation, however. You might be making what is called a multiple hypothesis testing error. If you try very many parameter settings, some of them will work better just by chance, and the score that you obtained might not reflect how your model would perform on new unseen data.\n",
    "Therefore, it is good to split off a separate test-set before performing grid-search. This pattern can be seen as a training-validation-test split, and is common in machine learning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/grid_search_cross_validation.svg\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do this very easily by splitting of some test data using ``train_test_split``, training ``GridSearchCV`` on the training set, and applying the ``score`` method to the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48807971012159346"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "cv = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=cv)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the parameters that were selected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 1}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some practitioners go for an easier scheme, splitting the data simply into three parts, training, validation and testing. This is a possible alternative if your training set is very large, or it is infeasible to train many models using cross-validation because training a model takes very long.\n",
    "You can do this with scikit-learn for example by splitting of a test-set and then applying GridSearchCV with ShuffleSplit cross-validation with a single iteration:\n",
    "\n",
    "<img src=\"figures/train_validation_test2.svg\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV]  C=0.001, gamma=0.001, score=-0.014436398677135864, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] . C=0.001, gamma=0.01, score=-0.012580651891246353, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] . C=0.001, gamma=0.1, score=-0.0038060061440357007, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ... C=0.001, gamma=1, score=-0.0045680710406688085, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] . C=0.01, gamma=0.001, score=-0.012411468106753087, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] ... C=0.01, gamma=0.01, score=0.006034376764599613, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ..... C=0.01, gamma=0.1, score=0.08694010755853143, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] ....... C=0.01, gamma=1, score=0.07978872040529716, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ... C=0.1, gamma=0.001, score=0.007707841498843514, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ..... C=0.1, gamma=0.01, score=0.17093044419816805, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ...... C=0.1, gamma=0.1, score=0.49882359779816804, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ......... C=0.1, gamma=1, score=0.4757108344400582, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ...... C=1, gamma=0.001, score=0.18528259444685435, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ........ C=1, gamma=0.01, score=0.5991910522344117, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ......... C=1, gamma=0.1, score=0.7503588306206886, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ............ C=1, gamma=1, score=0.707365349972864, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ...... C=10, gamma=0.001, score=0.5866137601709587, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ....... C=10, gamma=0.01, score=0.7009553488760285, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ........ C=10, gamma=0.1, score=0.7570970494619221, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .......... C=10, gamma=1, score=0.7655643246714823, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.48807971012159346"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "single_split_cv = ShuffleSplit(n_splits=1)\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=single_split_cv, verbose=3)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is much faster, but might result in worse hyperparameters and therefore worse results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48807971012159346"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(SVR(), param_grid=param_grid)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISE</b>:\n",
    "     <ul>\n",
    "      <li>\n",
    "      Apply grid-search to find the best setting for the number of neighbors in ``KNeighborsClassifier``, and apply it to the digits dataset.\n",
    "      </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()\n",
    "X,y = digits.data, digits.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_neighbors':[1,2,5,8,12,20]}\n",
    "clf = GridSearchCV(KNeighborsClassifier(),params,cv=5,verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] .......................... n_neighbors=1, score=0.985401 -   0.0s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] .......................... n_neighbors=1, score=0.988889 -   0.1s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] .......................... n_neighbors=1, score=0.996296 -   0.0s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] .......................... n_neighbors=1, score=0.996269 -   0.0s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] .......................... n_neighbors=1, score=0.981132 -   0.0s\n",
      "[CV] n_neighbors=2 ...................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......................... n_neighbors=2, score=0.981752 -   0.0s\n",
      "[CV] n_neighbors=2 ...................................................\n",
      "[CV] .......................... n_neighbors=2, score=0.974074 -   0.0s\n",
      "[CV] n_neighbors=2 ...................................................\n",
      "[CV] .......................... n_neighbors=2, score=0.985185 -   0.0s\n",
      "[CV] n_neighbors=2 ...................................................\n",
      "[CV] .......................... n_neighbors=2, score=0.992537 -   0.0s\n",
      "[CV] n_neighbors=2 ...................................................\n",
      "[CV] .......................... n_neighbors=2, score=0.981132 -   0.0s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] .......................... n_neighbors=5, score=0.970803 -   0.0s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] .......................... n_neighbors=5, score=0.985185 -   0.0s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] .......................... n_neighbors=5, score=0.962963 -   0.0s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] .......................... n_neighbors=5, score=0.988806 -   0.0s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] .......................... n_neighbors=5, score=0.992453 -   0.0s\n",
      "[CV] n_neighbors=8 ...................................................\n",
      "[CV] .......................... n_neighbors=8, score=0.967153 -   0.0s\n",
      "[CV] n_neighbors=8 ...................................................\n",
      "[CV] .......................... n_neighbors=8, score=0.974074 -   0.0s\n",
      "[CV] n_neighbors=8 ...................................................\n",
      "[CV] .......................... n_neighbors=8, score=0.955556 -   0.0s\n",
      "[CV] n_neighbors=8 ...................................................\n",
      "[CV] .......................... n_neighbors=8, score=0.988806 -   0.0s\n",
      "[CV] n_neighbors=8 ...................................................\n",
      "[CV] .......................... n_neighbors=8, score=0.988679 -   0.0s\n",
      "[CV] n_neighbors=12 ..................................................\n",
      "[CV] ......................... n_neighbors=12, score=0.959854 -   0.0s\n",
      "[CV] n_neighbors=12 ..................................................\n",
      "[CV] ......................... n_neighbors=12, score=0.970370 -   0.0s\n",
      "[CV] n_neighbors=12 ..................................................\n",
      "[CV] ......................... n_neighbors=12, score=0.951852 -   0.0s\n",
      "[CV] n_neighbors=12 ..................................................\n",
      "[CV] ......................... n_neighbors=12, score=0.988806 -   0.0s\n",
      "[CV] n_neighbors=12 ..................................................\n",
      "[CV] ......................... n_neighbors=12, score=0.984906 -   0.0s\n",
      "[CV] n_neighbors=20 ..................................................\n",
      "[CV] ......................... n_neighbors=20, score=0.948905 -   0.0s\n",
      "[CV] n_neighbors=20 ..................................................\n",
      "[CV] ......................... n_neighbors=20, score=0.970370 -   0.0s\n",
      "[CV] n_neighbors=20 ..................................................\n",
      "[CV] ......................... n_neighbors=20, score=0.944444 -   0.0s\n",
      "[CV] n_neighbors=20 ..................................................\n",
      "[CV] ......................... n_neighbors=20, score=0.977612 -   0.0s\n",
      "[CV] n_neighbors=20 ..................................................\n",
      "[CV] ......................... n_neighbors=20, score=0.984906 -   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [1, 2, 5, 8, 12, 20]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=3)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 2} 0.9666110183639399\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_params_, clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] .......................... n_neighbors=1, score=0.970803 -   0.0s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] .......................... n_neighbors=1, score=0.988930 -   0.0s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] .......................... n_neighbors=1, score=0.988930 -   0.0s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] .......................... n_neighbors=1, score=0.988764 -   0.0s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] .......................... n_neighbors=1, score=0.988636 -   0.0s\n",
      "[CV] n_neighbors=3 ...................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......................... n_neighbors=3, score=0.981752 -   0.0s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] .......................... n_neighbors=3, score=0.988930 -   0.0s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] .......................... n_neighbors=3, score=0.985240 -   0.0s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] .......................... n_neighbors=3, score=0.985019 -   0.0s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] .......................... n_neighbors=3, score=0.984848 -   0.0s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] .......................... n_neighbors=5, score=0.985401 -   0.0s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] .......................... n_neighbors=5, score=0.996310 -   0.0s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] .......................... n_neighbors=5, score=0.974170 -   0.0s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] .......................... n_neighbors=5, score=0.985019 -   0.0s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] .......................... n_neighbors=5, score=0.984848 -   0.0s\n",
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] ......................... n_neighbors=10, score=0.978102 -   0.0s\n",
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] ......................... n_neighbors=10, score=0.981550 -   0.0s\n",
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] ......................... n_neighbors=10, score=0.977860 -   0.0s\n",
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] ......................... n_neighbors=10, score=0.981273 -   0.0s\n",
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] ......................... n_neighbors=10, score=0.984848 -   0.0s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ......................... n_neighbors=50, score=0.927007 -   0.1s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ......................... n_neighbors=50, score=0.929889 -   0.1s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ......................... n_neighbors=50, score=0.952030 -   0.1s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ......................... n_neighbors=50, score=0.921348 -   0.1s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ......................... n_neighbors=50, score=0.958333 -   0.1s\n",
      "Score on test set: 0.991111\n",
      "Best parameters: {'n_neighbors': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    1.0s finished\n"
     ]
    }
   ],
   "source": [
    "# %load solutions/14_grid_search.py\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "digits = load_digits()\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, random_state=0)\n",
    "\n",
    "param_grid = {'n_neighbors': [1, 3, 5, 10, 50]}\n",
    "gs = GridSearchCV(KNeighborsClassifier(), param_grid=param_grid, cv=5, verbose=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print(\"Score on test set: %f\" % gs.score(X_test, y_test))\n",
    "print(\"Best parameters: %s\" % gs.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 1} 0.9851521900519673\n"
     ]
    }
   ],
   "source": [
    "print(gs.best_params_, gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
